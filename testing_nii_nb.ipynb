{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torchvision.models import vgg11_bn, VGG11_BN_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = VGG11_BN_Weights.DEFAULT\n",
    "model = vgg11_bn(weights=weights).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the trainer and evaluaF.nll_loss(output, target, reduction='sum').item()tor\n",
    "def trainer(model, optimizer, criterion, train_loader):\n",
    "    # training the model\n",
    "    model.train()\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def evaluator(model, test_loader):\n",
    "    # evaluating the model accuracy and average test loss\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_dataset_length = 64\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += loss(output, target)\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            break\n",
    "    test_loss /= test_dataset_length\n",
    "    accuracy = 100. * correct / test_dataset_length\n",
    "    print('Average test loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(test_loss, correct, test_dataset_length, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 0.3423, Accuracy: 0/64 (0%)\n"
     ]
    }
   ],
   "source": [
    "evaluator(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [{\n",
    "    'op_types': ['Conv2d', \"Linear\"],\n",
    "    'exclude_op_names': ['classifier.6'],\n",
    "    'sparse_ratio': 0.5\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_nni_wrapper): ModuleWrapper(module=Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), module_name=features.0)\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_nni_wrapper): ModuleWrapper(module=Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), module_name=features.4)\n",
      "    )\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_nni_wrapper): ModuleWrapper(module=Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), module_name=features.8)\n",
      "    )\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_nni_wrapper): ModuleWrapper(module=Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), module_name=features.11)\n",
      "    )\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(\n",
      "      256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_nni_wrapper): ModuleWrapper(module=Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), module_name=features.15)\n",
      "    )\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_nni_wrapper): ModuleWrapper(module=Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), module_name=features.18)\n",
      "    )\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_nni_wrapper): ModuleWrapper(module=Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), module_name=features.22)\n",
      "    )\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_nni_wrapper): ModuleWrapper(module=Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), module_name=features.25)\n",
      "    )\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(\n",
      "      in_features=512, out_features=4096, bias=True\n",
      "      (_nni_wrapper): ModuleWrapper(module=Linear(in_features=512, out_features=4096, bias=True), module_name=classifier.0)\n",
      "    )\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(\n",
      "      in_features=4096, out_features=4096, bias=True\n",
      "      (_nni_wrapper): ModuleWrapper(module=Linear(in_features=4096, out_features=4096, bias=True), module_name=classifier.3)\n",
      "    )\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from nni.compression.pruning import L1NormPruner, L2NormPruner\n",
    "pruner = L2NormPruner(model, config_list)\n",
    "\n",
    "# show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.11  sparsity :  0.5\n",
      "features.0  sparsity :  0.5\n",
      "features.18  sparsity :  0.5\n",
      "features.22  sparsity :  0.5\n",
      "features.4  sparsity :  0.5\n",
      "features.8  sparsity :  0.5\n",
      "features.15  sparsity :  0.5\n",
      "features.25  sparsity :  0.5\n",
      "classifier.3  sparsity :  0.5\n",
      "classifier.0  sparsity :  0.5\n"
     ]
    }
   ],
   "source": [
    "# compress the model and generate the masks\n",
    "_, masks = pruner.compress()\n",
    "# show the masks sparsity\n",
    "for name, mask in masks.items():\n",
    "    print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-18 14:12:25] \u001b[32mStart to speedup the model...\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mResolve the mask conflict before mask propagate...\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "0 Filter\n",
      "[2023-09-18 14:12:25] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mInfer module masks...\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate original variables\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_0, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_1, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_2, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_3, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_4, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_5, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_6, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_7, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_8, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_9, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_10, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_11, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_12, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_13, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_14, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_15, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_16, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_17, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_18, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_19, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_20, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_21, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_22, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_23, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_24, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_25, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_26, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_27, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: features_28, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: avgpool, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_method: size, \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_method: view, output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: classifier_0, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: classifier_1, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: classifier_2, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: classifier_3, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: classifier_4, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: classifier_5, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for call_module: classifier_6, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mPropagate variables for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct sparsity...\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_0, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_1, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_2, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_3, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_4, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_5, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_6, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_7, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_8, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_9, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_10, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_11, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_12, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_13, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_14, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_15, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_16, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_17, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_18, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_19, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_20, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_21, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_22, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_23, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_24, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_25, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_26, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_27, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: features_28, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: avgpool, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_method: size, \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_method: view, output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: classifier_0, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: classifier_1, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: classifier_2, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: classifier_3, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: classifier_4, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: classifier_5, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for call_module: classifier_6, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate direct mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect sparsity...\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: classifier_6, , output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: classifier_5, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: classifier_4, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: classifier_3, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: classifier_2, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: classifier_1, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: classifier_0, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_method: view, output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_method: size, \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: avgpool, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_28, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_27, , output mask:  0.5498 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_26, , output mask:  0.5498 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_25, weight:  0.7617 bias:  0.5000 , output mask:  0.5498 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_24, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_23, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_22, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_21, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_20, , output mask:  0.5516 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_19, , output mask:  0.5516 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_18, weight:  0.7500 bias:  0.5000 , output mask:  0.5516 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_17, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_16, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_15, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_14, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_13, , output mask:  0.5480 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_12, , output mask:  0.5480 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_11, weight:  0.7500 bias:  0.5000 , output mask:  0.5480 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_10, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_9, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_8, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_7, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_6, , output mask:  0.5502 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_5, , output mask:  0.5502 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_4, weight:  0.7500 bias:  0.5000 , output mask:  0.5502 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_3, , output mask:  0.5000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_2, , output mask:  0.5491 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_1, , output mask:  0.5491 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for call_module: features_0, weight:  0.5000 bias:  0.5000 , output mask:  0.5491 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mUpdate indirect mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mResolve the mask conflict after mask propagate...\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mdim1 sparsity: 0.499331\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "0 Filter\n",
      "[2023-09-18 14:12:25] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mdim1 sparsity: 0.499331\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mReplace compressed modules...\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_0, op_type: Conv2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace conv2d with in_channels: 3, out_channels: 32\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace batchnorm2d with num_features: 32\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_2, op_type: ReLU)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_3, op_type: MaxPool2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_4, op_type: Conv2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace conv2d with in_channels: 32, out_channels: 64\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_5, op_type: BatchNorm2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace batchnorm2d with num_features: 64\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_6, op_type: ReLU)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_7, op_type: MaxPool2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_8, op_type: Conv2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace conv2d with in_channels: 64, out_channels: 128\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_9, op_type: BatchNorm2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace batchnorm2d with num_features: 128\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_10, op_type: ReLU)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_11, op_type: Conv2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace conv2d with in_channels: 128, out_channels: 128\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_12, op_type: BatchNorm2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace batchnorm2d with num_features: 128\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_13, op_type: ReLU)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_14, op_type: MaxPool2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_15, op_type: Conv2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace conv2d with in_channels: 128, out_channels: 256\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_16, op_type: BatchNorm2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace batchnorm2d with num_features: 256\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_17, op_type: ReLU)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_18, op_type: Conv2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace conv2d with in_channels: 256, out_channels: 256\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_19, op_type: BatchNorm2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace batchnorm2d with num_features: 256\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_20, op_type: ReLU)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_21, op_type: MaxPool2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_22, op_type: Conv2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace conv2d with in_channels: 256, out_channels: 256\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_23, op_type: BatchNorm2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace batchnorm2d with num_features: 256\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_24, op_type: ReLU)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_25, op_type: Conv2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace conv2d with in_channels: 256, out_channels: 256\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_26, op_type: BatchNorm2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace batchnorm2d with num_features: 256\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_27, op_type: ReLU)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: features_28, op_type: MaxPool2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: avgpool, op_type: AdaptiveAvgPool2d)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: classifier_0, op_type: Linear)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace linear with new in_features: 256, out_features: 2048\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: classifier_1, op_type: ReLU)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: classifier_2, op_type: Dropout)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: classifier_3, op_type: Linear)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace linear with new in_features: 2048, out_features: 2048\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: classifier_4, op_type: ReLU)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: classifier_5, op_type: Dropout)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace module (name: classifier_6, op_type: Linear)\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mreplace linear with new in_features: 2048, out_features: 10\u001b[0m\n",
      "[2023-09-18 14:12:25] \u001b[32mSpeedup done.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to unwrap the model, if the model is wrapped before speedup\n",
    "pruner.unwrap_model()\n",
    "\n",
    "# speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
    "from nni.compression.speedup import ModelSpeedup\n",
    "\n",
    "ModelSpeedup(model, torch.rand(64, 3, 32, 32).to(device), masks).speedup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=2048, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), 1e-2)\n",
    "for epoch in range(17):\n",
    "    trainer(model, optimizer, criterion, trainloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 0.0092, Accuracy: 53/64 (83%)\n"
     ]
    }
   ],
   "source": [
    "evaluator(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
